% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/JSTOR_unpack_multiple_archives.R
\name{JSTOR_unpack_multiple_archives}
\alias{JSTOR_unpack_multiple_archives}
\title{Plot the most frequent words by time intervals}
\usage{
JSTOR_unpack_multiple_archives(mydir = getwd())
}
\arguments{
\item{mydir}{path to directory containing multiple zip files dowloaded from dfr.jstor.org (default is the current working directory)}

\item{nouns}{the object returned by the function JSTOR_dtmofnouns. A Document Term Matrix of nouns.}

\item{n}{the number years to aggregate documents by. For example, n = 5 (the default value) will create groups of all documents published in non-overlapping five year ranges.}

\item{lowfreq}{An integer for the minimum frequency of a word to be included in the plot. Default is 300.}

\item{topn}{An integer for the number of top ranking words to plot. For example, topn = 20 (the default value) will plot the top 20 words for each range of years.}

\item{biggest}{An integer to control the maximum size of the text in the plot}
}
\value{
Returns a list of two items. First is "wordcounts", a Document Term Matrix of 1-grams, and second is 'bibliodata', a data frame of bibliographic information for all articles.
}
\description{
Generates a plot of the top n words in all the documents in ranges of years. For use with JSTOR's Data for Research datasets (http://dfr.jstor.org/). For best results, repeat the function several times after adding common words to the stopword list and excluding them by re-running the JSTOR_dtmofnouns function. The location of the English stopwords list can be found by entering this at the R prompt: paste0(.libPaths()[1], "/tm/stopwords/english.dat")
}
\examples{
## multiple_archives <- JSTOR_unpack_multiple_archives(mydir = "~/my_data")
}

